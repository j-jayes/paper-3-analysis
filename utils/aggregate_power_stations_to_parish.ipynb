{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "Aggregate the data about the power stations into a single file at the parish level in order to do the first-stage analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change shapefile to geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "root = pathlib.Path.cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_file_path = root / \"data/maps/Swedish_parishes_1926.shp\"\n",
    "\n",
    "# Read the shapefile\n",
    "gdf = gpd.read_file(shp_file_path)\n",
    "\n",
    "# Convert to GeoJSON in root, data/maps/Swedish_parishes_1926.geojson\n",
    "gdf.to_file(root / \"data/maps/Swedish_parishes_1926.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Read the Excel file\n",
    "power_stations_df = pd.read_excel(root / \"data/power-stations/power-stations.xlsx\")\n",
    "\n",
    "# Read the GeoJSON file\n",
    "parishes_gdf = gpd.read_file(root / \"data/maps/Swedish_parishes_1926.geojson\")\n",
    "\n",
    "\n",
    "# Convert the power stations data into a GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(power_stations_df['longitude'], power_stations_df['latitude'])]\n",
    "power_stations_gdf = gpd.GeoDataFrame(power_stations_df, geometry=geometry)\n",
    "power_stations_gdf.set_crs(\"EPSG:4326\", inplace=True, allow_override=True)\n",
    "power_stations_gdf = power_stations_gdf.to_crs(parishes_gdf.crs)\n",
    "\n",
    "# Perform the spatial join between the parishes and the power stations where the power stations are within the parishes\n",
    "joined_gdf = gpd.sjoin(parishes_gdf, power_stations_gdf, how=\"inner\", op=\"contains\")\n",
    "\n",
    "# Group by the parish ref_code and name, and the source of power to calculate the number of power stations and the total amount of power for each source\n",
    "source_stats = joined_gdf.groupby(['ref_code', 'name_left', 'source_final']).agg({'amount_final': ['count', 'sum']}).reset_index()\n",
    "source_stats.columns = ['Ref Code', 'Parish', 'Source', 'Number of Stations', 'Total Power']\n",
    "\n",
    "# Pivot the source_stats DataFrame to create new columns for each source type\n",
    "pivot_source_stats = source_stats.pivot_table(index=['Ref Code', 'Parish'], columns='Source', values=['Number of Stations', 'Total Power'], fill_value=0).reset_index()\n",
    "# Flatten the MultiIndex columns\n",
    "pivot_source_stats.columns = [' '.join(col).strip() for col in pivot_source_stats.columns.values]\n",
    "# Reset the index\n",
    "pivot_source_stats.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# Calculate the total number of power stations and the total amount of power in each parish\n",
    "total_stats = joined_gdf.groupby(['ref_code', 'name_left']).agg({'amount_final': ['count', 'sum']}).reset_index()\n",
    "total_stats.columns = ['Ref Code', 'Parish', 'Total Stations', 'Total Power']\n",
    "\n",
    "pivot_source_stats, total_stats\n",
    "\n",
    "# Merge the pivot_source_stats and total_stats DataFrames\n",
    "final_df = pd.merge(pivot_source_stats, total_stats, on=['Ref Code', 'Parish'])\n",
    "\n",
    "parishes_gdf_to_join = parishes_gdf[['ref_code', 'name']]\n",
    "# rename the columns to match the final_df\n",
    "parishes_gdf_to_join.columns = ['Ref Code', 'Parish']\n",
    "\n",
    "final_df_all_parishes = parishes_gdf_to_join.merge(final_df, how='left', left_on=['Ref Code', 'Parish'], right_on=['Ref Code', 'Parish'])\n",
    "\n",
    "# Get the column names excluding 'Ref Code' and 'Parish'\n",
    "columns_to_fill = [col for col in final_df_all_parishes.columns if col not in ['Ref Code', 'Parish']]\n",
    "\n",
    "# Replace NaN values with 0\n",
    "final_df_all_parishes[columns_to_fill] = final_df_all_parishes[columns_to_fill].fillna(0)\n",
    "\n",
    "final_df_all_parishes.head()\n",
    "\n",
    "# sample the data\n",
    "final_df_all_parishes.sample(10)\n",
    "\n",
    "final_df_all_parishes.columns\n",
    "\n",
    "# Rename the columns to snake_case with a fomula\n",
    "final_df_all_parishes.columns = [col.lower().replace(' ', '_') for col in final_df_all_parishes.columns]\n",
    "\n",
    "# Save the final_df_all_parishes DataFrame as a CSV file with utf-8 encoding\n",
    "final_df_all_parishes.to_csv(root / \"data/power-stations/power-stations-by-parish.csv\", index=False, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get parish area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(root / \"data/power-stations/power-stations-by-parish.csv\")\n",
    "\n",
    "parishes_gdf = gpd.read_file(root / \"data/maps/Swedish_parishes_1926.geojson\")\n",
    "\n",
    "# calculate parish area\n",
    "parishes_gdf['area'] = parishes_gdf.area\n",
    "\n",
    "# select ref_code, area, geom_id\n",
    "parishes_gdf = parishes_gdf[['ref_code', 'area', 'geom_id']]\n",
    "\n",
    "# merge df and parishes_gdf on ref_code\n",
    "\n",
    "df = df.merge(parishes_gdf, on='ref_code', how='left')\n",
    "\n",
    "df.to_csv(root / \"data/power-stations/power-stations-by-parish_with_area.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join treatment parishes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(root / \"data/power-stations/power-stations-by-parish_with_area.csv\")\n",
    "\n",
    "treated_parishes = pd.read_excel(root / \"data/parishes/treated_parishes.xlsx\")\n",
    "\n",
    "# prepend \"SE/\" to parish_code and call it ref_code, add a leading zero to parish_code if it is less than 9 characters\n",
    "treated_parishes['ref_code'] = treated_parishes['parish_code'].apply(lambda x: 'SE/' + str(x).zfill(9))\n",
    "# keep only ref_code and iline, rename iline to treated\n",
    "treated_parishes = treated_parishes[['ref_code', 'iline']]\n",
    "treated_parishes = treated_parishes.rename(columns={'iline': 'treated'})\n",
    "\n",
    "# join df and treated_parishes on ref_code\n",
    "df = df.merge(treated_parishes, on='ref_code', how='left')\n",
    "\n",
    "# fill NaN values in treated with 0 in treated\n",
    "df['treated'] = df['treated'].fillna(0)\n",
    "\n",
    "df.to_csv(root / \"data/power-stations/power-stations-by-parish_with_area_and_treated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must add in the distance from the central line to the center of the parish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, LineString\n",
    "\n",
    "parishes_gdf = gpd.read_file(root / \"data/maps/Swedish_parishes_1926.geojson\")\n",
    "\n",
    "parishes_gdf['centroid'] = parishes_gdf.geometry.centroid\n",
    "\n",
    "station1_coords = (12.272571287279908, 58.27550603306433)\n",
    "station2_coords = (17.443262677788724, 60.5633613884066)\n",
    "\n",
    "# Create line\n",
    "line = LineString([station1_coords, station2_coords])\n",
    "\n",
    "# Create a GeoDataFrame from the line\n",
    "line_gdf = gpd.GeoDataFrame(geometry=[line], crs='EPSG:4326')\n",
    "\n",
    "line_gdf = line_gdf.to_crs('EPSG:3006')\n",
    "parishes_gdf = parishes_gdf.to_crs('EPSG:3006')\n",
    "\n",
    "parishes_gdf['distance_to_line'] = parishes_gdf['centroid'].apply(lambda x: line_gdf.distance(x).min())\n",
    "\n",
    "# convert distance_to_line to km\n",
    "parishes_gdf['distance_to_line'] = parishes_gdf['distance_to_line'] / 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the parishes, color by distance to line\n",
    "parishes_gdf.plot(column='distance_to_line', cmap='YlOrRd', linewidth=0.8, ax=ax, legend=True)\n",
    "\n",
    "# Plot the line\n",
    "line_gdf.plot(color='blue', linewidth=2, ax=ax)\n",
    "\n",
    "# Set the title\n",
    "ax.set_title('Distance from Parishes to Line')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export from parishes_gdf just the ref_code and distance_to_line columns\n",
    "parishes_gdf[['ref_code', 'distance_to_line']].to_csv(root / \"data/parishes/distance_to_line.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to df on ref_code\n",
    "df = pd.read_csv(root / \"data/power-stations/power-stations-by-parish_with_area_and_treated.csv\")\n",
    "\n",
    "line_distance = pd.read_csv(root / \"data/parishes/distance_to_line.csv\")\n",
    "\n",
    "# merge df and line_distance on ref_code\n",
    "df = df.merge(line_distance, on='ref_code', how='left')\n",
    "\n",
    "df.to_csv(root / \"data/power-stations/power-stations-by-parish_with_area_and_treated_and_distance_to_line.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must find out of a parish is touching a treated parish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in df\n",
    "df = pd.read_csv(root / \"data/power-stations/power-stations-by-parish_with_area_and_treated_and_distance_to_line.csv\")\n",
    "\n",
    "# read in geojson file\n",
    "parishes_gdf = gpd.read_file(root / \"data/maps/Swedish_parishes_1926.geojson\")\n",
    "# keep only ref_code and geometry\n",
    "parishes_gdf = parishes_gdf[['ref_code', 'geometry']]\n",
    "\n",
    "# join df and parishes_gdf on ref_code\n",
    "df = df.merge(parishes_gdf, on='ref_code', how='left')\n",
    "\n",
    "df = gpd.GeoDataFrame(df, geometry='geometry', crs='EPSG:3006')\n",
    "\n",
    "# Assuming df is a GeoDataFrame\n",
    "treated = df[df['treated'] == 1]\n",
    "\n",
    "def touches_treated(geometry):\n",
    "    return treated.touches(geometry).any()\n",
    "\n",
    "# return true = 1 if the geometry touches a treated parish, else return false = 0\n",
    "df['touching_treated'] = df['geometry'].apply(touches_treated).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we need to fix the touching treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df[\"touching_treated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Plot the parishes that are not treated and don't touch treated parishes\n",
    "df[(df['treated'] == 0) & (df['touching_treated'] == 0)].plot(ax=ax, color='white', edgecolor='black')\n",
    "\n",
    "# Plot the parishes that are treated\n",
    "df[df['treated'] == 1].plot(ax=ax, color='red', edgecolor='black')\n",
    "\n",
    "# Plot the parishes that are not treated but touch treated parishes\n",
    "df[(df['treated'] == 0) & (df['touching_treated'] == 1)].plot(ax=ax, color='yellow', edgecolor='black')\n",
    "\n",
    "# Set the title\n",
    "ax.set_title(\"Parish Treatment Map\", fontsize=18)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop geometry column\n",
    "df = df.drop(columns=['geometry'])\n",
    "\n",
    "# write out\n",
    "df.to_csv(root / \"data/power-stations/power-stations-by-parish_with_area_and_treated_and_distance_to_line_and_touching_treated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to make a match between the parishes in the map and the parishes with population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = gpd.read_file(root / \"data/maps/Swedish_parishes_1926.geojson\")\n",
    "\n",
    "parish_df = pd.read_excel(root / \"data/parishes/cross-walk-1900-1910.xlsx\")\n",
    "\n",
    "# Convert ref_code_long to string and add leading zeros to make it 9 digits long\n",
    "parish_df['ref_code_long'] = parish_df['ref_code_long'].astype(str).str.zfill(9)\n",
    "\n",
    "# We need to extract the numeric part from ref_code in the geo_df\n",
    "geo_df['ref_code_num'] = geo_df['ref_code'].str.extract('(\\d+)')\n",
    "\n",
    "# Now perform the left join\n",
    "merged_df = geo_df.merge(parish_df, how='left', left_on='ref_code_num', right_on='ref_code_long', indicator=True)\n",
    "\n",
    "# Find out which entries from geo_df did not find a match in parish_df\n",
    "no_match_df = merged_df[merged_df['_merge'] == 'left_only']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "def fuzzy_merge(df_1, df_2, key1, key2, threshold=90, limit=1):\n",
    "    \"\"\"\n",
    "    :param df_1: the left table to join\n",
    "    :param df_2: the right table to join\n",
    "    :param key1: key column of the left table\n",
    "    :param key2: key column of the right table\n",
    "    :param threshold: how close the matches should be to return a match, based on Levenshtein distance\n",
    "    :param limit: the amount of matches that will get returned, these are sorted high to low\n",
    "    :return: dataframe with boths keys and matches\n",
    "    \"\"\"\n",
    "    s = df_2[key2].tolist()\n",
    "\n",
    "    m = df_1[key1].apply(lambda x: process.extract(x, s, limit=limit))    \n",
    "    df_1['matches'] = m\n",
    "\n",
    "    m2 = df_1['matches'].apply(lambda x: ', '.join([i[0] for i in x if i[1] >= threshold]))\n",
    "    df_1['matches'] = m2\n",
    "\n",
    "    return df_1\n",
    "\n",
    "# Create a new column in both dataframes with name and the first 4 digits of the ref_code\n",
    "no_match_df['name_code'] = no_match_df['name_x'] + ' ' + no_match_df['ref_code_num'].str[:4]\n",
    "parish_df['name_code'] = parish_df['name'] + ' ' + parish_df['ref_code_long'].str[:4]\n",
    "\n",
    "# Apply fuzzy matching\n",
    "fuzzy_match_df = fuzzy_merge(no_match_df, parish_df, 'name_code', 'name_code', threshold=90)\n",
    "\n",
    "# Display the fuzzy_match_df\n",
    "fuzzy_match_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First, let's create a new column in the merged_df to indicate the type of match\n",
    "merged_df['match_type'] = 'First Step Match'\n",
    "merged_df.loc[merged_df['_merge'] == 'left_only', 'match_type'] = 'Unmatched'\n",
    "\n",
    "# Then, let's update the match_type for the entries that were matched in the fuzzy matching step\n",
    "fuzzy_matched_indices = fuzzy_match_df[fuzzy_match_df['matches'] != ''].index\n",
    "merged_df.loc[merged_df.index.isin(fuzzy_matched_indices), 'match_type'] = 'Fuzzy Match'\n",
    "\n",
    "# Now, let's plot the parishes with different colors for each match_type\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "merged_df.plot(column='match_type', ax=ax, legend=True, categorical=True, legend_kwds={'loc': 'upper left'})\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Select unmatched power stations\n",
    "unmatched_df = merged_df[merged_df['match_type'] == 'Unmatched']\n",
    "\n",
    "# convert ref_code_num to int\n",
    "unmatched_df['ref_code_num'] = unmatched_df['ref_code_num'].astype(int)\n",
    "\n",
    "# convert ref_code_num to int in geo_df\n",
    "geo_df['ref_code_num'] = geo_df['ref_code_num'].astype(int)\n",
    "\n",
    "# Compute distance between unmatched ref_code_nums and geo_df ref_code_nums\n",
    "distances = cdist(unmatched_df[['ref_code_num']], geo_df[['ref_code_num']])\n",
    "\n",
    "\n",
    "# Find index of closest geo_df ref_code_num for each unmatched ref_code_num\n",
    "closest_idx = np.argmin(distances, axis=1)\n",
    "\n",
    "# Get ref_code_num and geom_id from geo_df for closest ref_code_nums\n",
    "closest_ref_codes = geo_df.loc[closest_idx, ['ref_code_num', 'geom_id']]\n",
    "\n",
    "# keep only matched rows of merged_df\n",
    "matched_df = merged_df[merged_df['match_type'] != 'Unmatched']\n",
    "\n",
    "# then select just ref_code_num and geom_id\n",
    "matched_df = matched_df[['ref_code_num', 'geom_id']]\n",
    "\n",
    "# concatenate closest_ref_codes to matched_df\n",
    "matched_df = pd.concat([matched_df, closest_ref_codes])\n",
    "\n",
    "# write matched_df to excel file\n",
    "matched_df.to_excel(root /\"data/parishes/1900_1910_census_map_merged_data.xlsx\", index=False)\n",
    "\n",
    "matched_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to fix the 1930 parish names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_census_1930 = pd.read_parquet(root / \"data/census/df_ref.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only arkbild and scbkod and lan from df_census_1930\n",
    "df_census_1930_parish_names = df_census_1930[['arkbild', 'scbkod', 'lan']]\n",
    "\n",
    "# rename columns arkbild and scbkod to name and ref_code\n",
    "df_census_1930_parish_names = df_census_1930_parish_names.rename(columns={'arkbild': 'name', 'scbkod': 'ref_code'})\n",
    "\n",
    "# keep only unique rows\n",
    "df_census_1930_parish_names = df_census_1930_parish_names.drop_duplicates()\n",
    "\n",
    "# export to excel file named \"data/parishes/census_1930_parish_names.xlsx\"\n",
    "df_census_1930_parish_names.to_excel(root / \"data/parishes/census_1930_parish_names.xlsx\", index=False)\n",
    "\n",
    "geo_df = gpd.read_file(root / \"data/maps/Swedish_parishes_1926.geojson\")\n",
    "\n",
    "# export columns geom_id, ref_code, name to csv\n",
    "geo_df[['geom_id', 'ref_code', 'name']].to_excel(root / \"data/parishes/map_1926_names.xlsx\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = pd.read_excel(root / \"data/parishes/census_1930_parish_names.xlsx\")\n",
    "map_data = pd.read_excel(root / \"data/parishes/map_1926_names.xlsx\")\n",
    "\n",
    "# Standardize the census data reference codes to 6 digits\n",
    "census_data[\"ref_code\"] = census_data[\"ref_code\"].astype(str).str.zfill(6)\n",
    "\n",
    "# Remove the \"SE/\" prefix from the map data reference codes\n",
    "map_data[\"ref_code\"] = map_data[\"ref_code\"].str.replace(\"SE/\", \"\")\n",
    "# now move the last three digits of ref_code to another column called \"ref_code_last_three\"\n",
    "map_data[\"ref_code_last_three\"] = map_data[\"ref_code\"].str[-3:]\n",
    "# now remove the last three digits from ref_code\n",
    "map_data[\"ref_code\"] = map_data[\"ref_code\"].str[:-3]\n",
    "\n",
    "# Merge the two datasets based on 'ref_code'\n",
    "merged_data = pd.merge(census_data, map_data, on='ref_code', how='left')\n",
    "\n",
    "# show rows in merged_data where name_y is Nan\n",
    "unmatched_census_data = merged_data[merged_data['name_y'].isna()]\n",
    "\n",
    "# convert ref_code to int in unmatched_census_data and map_data\n",
    "unmatched_census_data['ref_code'] = unmatched_census_data['ref_code'].astype(int)\n",
    "map_data['ref_code'] = map_data['ref_code'].astype(int)\n",
    "\n",
    "# for each row in unmatched_census_data, find the closest ref_code in map_data numerically\n",
    "for index, row in unmatched_census_data.iterrows():\n",
    "    closest_ref_code = map_data.loc[(map_data['ref_code'] - row['ref_code']).abs().argsort()[:1]]\n",
    "    # set name_y in unmatched_census_data to name in closest_ref_code\n",
    "    unmatched_census_data.loc[index, 'name_y'] = closest_ref_code['name'].values[0]\n",
    "    # set geom_id in unmatched_census_data to geom_id in closest_ref_code\n",
    "    unmatched_census_data.loc[index, 'geom_id'] = closest_ref_code['geom_id'].values[0]\n",
    "\n",
    "# keep geom_id, ref_code from unmatched_census_data\n",
    "unmatched_census_data = unmatched_census_data[['geom_id', 'ref_code']]\n",
    "\n",
    "# keep rows of merged_data where name_y is not Nan\n",
    "matched_census_data = merged_data[merged_data['name_y'].notna()]\n",
    "# keep geom_id, ref_code from matched_census_data\n",
    "matched_census_data = matched_census_data[['geom_id', 'ref_code']]\n",
    "\n",
    "# concatenate matched_census_data and unmatched_census_data\n",
    "merged_data = pd.concat([matched_census_data, unmatched_census_data])\n",
    "\n",
    "# write out merged_data to excel file named \"data/parishes/1930_census_map_merged_data.xlsx\"\n",
    "merged_data.to_excel(root / \"data/parishes/1930_census_map_merged_data.xlsx\", index=False)\n",
    "\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we want to join this population data to the parish data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 1930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count scbkod in df_census_1930 and create a dataframe with the counts with the column name \"population\" and the index name \"ref_code\"\n",
    "population_df_1930 = df_census_1930['scbkod'].value_counts().rename_axis('ref_code').reset_index(name='population')\n",
    "\n",
    "crosswalk_df = pd.read_excel(root / \"data/parishes/1930_census_map_merged_data.xlsx\")\n",
    "\n",
    "# join population_df_1930 with crosswalk_df on ref_code\n",
    "population_df_1930 = pd.merge(population_df_1930, crosswalk_df, on='ref_code', how='left')\n",
    "\n",
    "# generate column called year = 1930\n",
    "population_df_1930['year'] = 1930\n",
    "\n",
    "population_df_1930.to_excel(root / \"population_by_parish_1930_with_geom_id.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 1900 and 1910"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load population data\n",
    "population_df_1900_1910 = pd.read_excel(pathlib.Path(root / 'data/parishes/population_by_parish_1900_1910.xlsx'))\n",
    "# concatenate \"population_\" to contents of year\n",
    "population_df_1900_1910['year'] = population_df_1900_1910['year'].apply(lambda x: 'population_' + str(x))\n",
    "\n",
    "# join to geom_id, read in crosswalk from root /\"data/parishes/1900_1910_census_map_merged_data.xlsx\"\n",
    "crosswalk_df = pd.read_excel(root / \"data/parishes/1900_1910_census_map_merged_data.xlsx\")\n",
    "\n",
    "# generate ref_code = ref_code_num as a string variable and add a leading zero to ref_code_num to make it 9 digits, and prepend \"SE/\" to ref_code\n",
    "crosswalk_df['ref_code'] = crosswalk_df['ref_code_num'].astype(str).str.zfill(9)\n",
    "crosswalk_df['ref_code'] = 'SE/' + crosswalk_df['ref_code']\n",
    "\n",
    "# merge population_df_1900_1910 with crosswalk_df on ref_code\n",
    "population_df_1900_1910 = pd.merge(population_df_1900_1910, crosswalk_df, on='ref_code', how='left')\n",
    "\n",
    "# generate ref_code_num in population_df_1900_1910 as numberic variable\n",
    "population_df_1900_1910['ref_code_num'] = population_df_1900_1910['ref_code'].str[3:].astype(int)\n",
    "\n",
    "# where geom_id is null, find the closest ref_code in crosswalk_df numerically and set geom_id to geom_id in the closest ref_code\n",
    "for index, row in population_df_1900_1910.iterrows():\n",
    "    if pd.isnull(row['geom_id']):\n",
    "        closest_ref_code = crosswalk_df.loc[(crosswalk_df['ref_code_num'] - row['ref_code_num']).abs().argsort()[:1]]\n",
    "        population_df_1900_1910.loc[index, 'geom_id'] = closest_ref_code['geom_id'].values[0]\n",
    "\n",
    "# keep geom_id, ref_code, year, n from population_df_1900_1910\n",
    "population_df_1900_1910 = population_df_1900_1910[['geom_id', 'ref_code', 'year', 'n']]\n",
    "\n",
    "# extract the year from the year column\n",
    "population_df_1900_1910['year'] = population_df_1900_1910['year'].str[-4:].astype(int)\n",
    "# rename n to population\n",
    "population_df_1900_1910 = population_df_1900_1910.rename(columns={'n': 'population'})\n",
    "\n",
    "# write out population_df_1900_1910 to excel file named \"data/parishes/population_by_parish_1900_1910_with_geom_id.xlsx\"\n",
    "population_df_1900_1910.to_excel(root / \"data/parishes/population_by_parish_1900_1910_with_geom_id.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_1930 = pd.read_excel(root / \"population_by_parish_1930_with_geom_id.xlsx\") \n",
    "# rename population to population_1930\n",
    "population_1930 = population_1930.rename(columns={'population': 'population_1930'})\n",
    "# keep population_1930, geom_id\n",
    "population_1930 = population_1930[['geom_id', 'population_1930']]\n",
    "\n",
    "population_1900_1910 = pd.read_excel(root / \"data/parishes/population_by_parish_1900_1910_with_geom_id.xlsx\")\n",
    "# drop ref_code\n",
    "population_1900_1910 = population_1900_1910.drop(columns=['ref_code'])\n",
    "\n",
    "population_1900 = population_1900_1910[population_1900_1910['year'] == 1900]\n",
    "# rename population to population_1900\n",
    "population_1900 = population_1900.rename(columns={'population': 'population_1900'})\n",
    "# keep population_1900, geom_id\n",
    "population_1900 = population_1900[['geom_id', 'population_1900']]\n",
    "\n",
    "population_1910 = population_1900_1910[population_1900_1910['year'] == 1910]\n",
    "# rename population to population_1910\n",
    "population_1910 = population_1910.rename(columns={'population': 'population_1910'})\n",
    "# keep population_1910, geom_id\n",
    "population_1910 = population_1910[['geom_id', 'population_1910']]\n",
    "\n",
    "df = pd.read_csv(root / \"data/power-stations/power-stations-by-parish_with_area_and_treated_and_distance_to_line_and_touching_treated.csv\")\n",
    "\n",
    "# join df with population_1900 on geom_id\n",
    "df = pd.merge(df, population_1900, on='geom_id', how='left')\n",
    "# join df with population_1910 on geom_id\n",
    "df = pd.merge(df, population_1910, on='geom_id', how='left')\n",
    "# join df with population_1930 on geom_id\n",
    "df = pd.merge(df, population_1930, on='geom_id', how='left')\n",
    "\n",
    "# drop index column from df\n",
    "df = df.drop(columns=['index'])\n",
    "\n",
    "# write out df to excel file named \"data/power-stations/power-stations-by-parish_with_area_and_treated_and_distance_to_line_and_touching_treated_and_population.xlsx\"\n",
    "df.to_excel(root / \"data/first-stage/parish-level-power-station-data.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to use this crosswalk to join to the population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the wrong labels\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(root / \"data/first-stage/parish-level-power-station-data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2093760417.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    df[\"touching_treated_new\"] = 0 if (df[\"touching_treated\"] == 1 & df[\"treated\"] == 1)\u001b[0m\n\u001b[1;37m                                                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fix\n",
    "df[\"touching_treated_new\"] = df[\"touching_treated\"]\n",
    "df[\"touching_treated_new\"] = 0 if (df[\"touching_treated\"] == 1 & df[\"treated\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set a DataFrame with multiple columns to the single column touching_treated_new",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17916\\2785743320.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;31m# create a new column called \"touching_treated_new\" and set it to touching treated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"touching_treated_new\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"touching_treated\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# replace touching_treated_new = 0 if touching_treated = 1 and treated = 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'touching_treated'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'treated'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'touching_treated_new'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\Documents\\Recon\\paper-3-analysis\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3936\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3937\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3938\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3940\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3941\u001b[0m         elif (\n\u001b[0;32m   3942\u001b[0m             \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3943\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\Documents\\Recon\\paper-3-analysis\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4090\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marraylike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4091\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4093\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4094\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   4095\u001b[0m                 \u001b[1;34m\"Cannot set a DataFrame with multiple columns to the single \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4096\u001b[0m                 \u001b[1;34mf\"column {key}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4097\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set a DataFrame with multiple columns to the single column touching_treated_new"
     ]
    }
   ],
   "source": [
    "# create a new column called \"touching_treated_new\" and set it to touching treated\n",
    "df[\"touching_treated_new\"] = df[\"touching_treated\"]\n",
    "# replace touching_treated_new = 0 if touching_treated = 1 and treated = 1\n",
    "df.loc[(df['touching_treated'] == 1) & (df['treated'] == 1), 'touching_treated_new'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rename touching_treated_new to touching_treated\n",
    "df = df.rename(columns={'touching_treated_new': 'touching_treated'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"total_power_water_new\"] = df[\"total_power_water\"]\n",
    "df[\"total_power_transmitted_new\"] = df[\"total_power_transmitted\"]\n",
    "\n",
    "df[\"total_power_water\"] = df[\"total_power_transmitted_new\"]\n",
    "df[\"total_power_transmitted\"] = df[\"total_power_water_new\"]\n",
    "\n",
    "df = df.drop([\"total_power_transmitted_new\", \"total_power_water_new\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"number_of_stations_water_new\"] = df[\"number_of_stations_water\"]\n",
    "df[\"number_of_stations_transmitted_new\"] = df[\"number_of_stations_transmitted\"]\n",
    "\n",
    "df[\"number_of_stations_water\"] = df[\"number_of_stations_transmitted_new\"]\n",
    "df[\"number_of_stations_transmitted\"] = df[\"number_of_stations_water_new\"]\n",
    "\n",
    "df = df.drop([\"number_of_stations_transmitted_new\", \"number_of_stations_water_new\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"total_power_generated\"] = df[\"total_power_diesel\"] + df[\"total_power_steam\"] + df[\"total_power_water\"]\n",
    "df[\"number_of_stations_generated\"] = df[\"number_of_stations_diesel\"] + df[\"number_of_stations_steam\"] + df[\"number_of_stations_water\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(root / \"data/first-stage/test-parish-level-power-station-data.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
